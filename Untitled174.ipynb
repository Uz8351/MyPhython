{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1UlGJ9Ai7RfM2V3gvO84G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uz8351/MyPhython/blob/master/Untitled174.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUfYQUa_eVtf",
        "outputId": "cf375755-c6a2-486f-8296-7deea5172d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores: [[ 0.60225518  0.1906965   0.07042661]\n",
            " [ 0.59331636  0.70272921  0.14867075]\n",
            " [-1.26023002 -1.04681381  0.72098027]]\n",
            "\n",
            "\n",
            "layer_1 [[-0.65797484 -0.85611731  0.79140687]\n",
            " [-0.66691366 -0.3440846   0.86965101]\n",
            " [ 0.60225518  0.1906965   0.07042661]]\n",
            "\n",
            "\n",
            "layer_1_act [[0.         0.         0.79140687]\n",
            " [0.         0.         0.86965101]\n",
            " [0.60225518 0.1906965  0.07042661]]\n",
            "\n",
            "\n",
            "PESOS CAPA DE SALIDA [[ 0.11350383]\n",
            " [-0.38653441]\n",
            " [-0.01648079]]\n",
            "\n",
            "\n",
            "Aplicando pesos a la salida: [[-0.01304301]\n",
            " [-0.01433253]\n",
            " [-0.00651318]]\n",
            "\n",
            "\n",
            "OUTPUT CON RELU [[0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Importación de librerías: Importamos la librería numpy con\n",
        "el alias np. Numpy es una biblioteca de Python para el cálculo\n",
        " numérico y nos permite realizar operaciones eficientes con matrices y vectores.\n",
        "\n",
        "Definición de datos de entrada (X): Se define una matriz X con\n",
        "dimensiones (3, 3). Cada fila representa un ejemplo de entrada\n",
        "para la red neuronal. En este caso, hay tres ejemplos, y cada uno tiene tres características.\n",
        "\n",
        "Inicialización de pesos de la capa oculta (W1): Se crea una\n",
        "matriz W1 con dimensiones (3, 3) utilizando np.random.randn().\n",
        "Los valores de esta matriz son números aleatorios\n",
        "generados siguiendo una distribución normal (gaussiana)\n",
        "con media 0 y varianza 1. Estos pesos representan los\n",
        "parámetros que la red neuronal aprenderá durante el entrenamiento.\n",
        "\n",
        "Definición de la función de activación ReLU: Se define una\n",
        "función llamada relu(x) que implementa la función de activación\n",
        "ReLU (Rectified Linear Unit). La función ReLU se define como relu(x) = max(0, x),\n",
        "lo que significa que cualquier valor menor o igual a cero se convierte en cero,\n",
        "y cualquier valor mayor a cero permanece sin cambios.\n",
        "\n",
        "Propagación hacia adelante en la capa oculta: Se realiza la propagación\n",
        "hacia adelante para obtener la salida de la capa oculta (layer_1_act).\n",
        "Primero, se realiza la multiplicación de las entradas (X) con los pesos\n",
        "de la capa oculta (W1) usando np.dot(), que es la operación de producto punto.\n",
        "Luego, se aplica la función de activación ReLU a la salida resultante.\n",
        "\n",
        "Inicialización de pesos de la capa de salida (W2): Se crea una matriz W2\n",
        "con dimensiones (3, 1) utilizando np.random.randn().\n",
        "Al igual que en el paso 3, estos pesos también se inicializan\n",
        "con valores aleatorios siguiendo una distribución normal.\n",
        "\n",
        "Propagación hacia adelante en la capa de salida: Se realiza\n",
        "la propagación hacia adelante en la capa de salida para obtener\n",
        "la salida final (output). Primero, se realiza la multiplicación\n",
        "de la salida de la capa oculta activada (layer_1_act) con los\n",
        "pesos de la capa de salida (W2) utilizando np.dot().\n",
        "\n",
        "Aplicación de la función de activación ReLU en la capa de salida:\n",
        "Después de obtener la salida de la capa de salida, se aplica nuevamente\n",
        "la función de activación ReLU a la salida final. Esto puede no ser necesario\n",
        "para todos los problemas, pero en este caso, se realiza para asegurarse\n",
        "de que la salida sea siempre no negativa.\n",
        "\n",
        "Impresión del resultado: Finalmente,\n",
        "el programa imprime la salida final de la red neuronal.\n",
        "\n",
        "El programa que has proporcionado es un ejemplo simple\n",
        "de propagación hacia adelante en una red neuronal con una\n",
        "capa oculta y una función de activación ReLU. Ten en cuenta\n",
        "que este programa no incluye la fase de entrenamiento (retropropagación)\n",
        "ni una función de pérdida para el aprendizaje supervisado.\n",
        "Estos aspectos son esenciales para que una red neuronal aprenda\n",
        "y mejore su rendimiento en tareas específicas.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "from os import pardir\n",
        "import numpy as np\n",
        "X = np.array([[1, 0, 1],\n",
        "              [0, 1, 1],\n",
        "              [1, 0, 0]])\n",
        "\n",
        "W1 = np.random.randn(3, 3)\n",
        "print(\"Valores:\",W1)\n",
        "print('\\n')\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "layer_1 = np.dot(X, W1)\n",
        "layer_1_act = relu(layer_1)\n",
        "print(\"layer_1\",layer_1)\n",
        "print('\\n')\n",
        "\n",
        "print(\"layer_1_act\",layer_1_act)\n",
        "W2 = np.random.randn(3, 1)\n",
        "print('\\n')\n",
        "\n",
        "print(\"PESOS CAPA DE SALIDA\",W2)\n",
        "output = np.dot(layer_1_act, W2)\n",
        "print('\\n')\n",
        "\n",
        "print(\"Aplicando pesos a la salida:\",output)\n",
        "output = relu(output)\n",
        "print('\\n')\n",
        "\n",
        "print(\"OUTPUT CON RELU\",output)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFNIcJ_Kk-_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}